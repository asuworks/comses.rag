{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T22:50:43.795160Z",
     "start_time": "2025-01-25T22:50:43.784882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DocSection:\n",
    "    id: str\n",
    "    parent_id: str\n",
    "    title: str\n",
    "    content: str\n",
    "\n",
    "def create_doc_sections_map(doc_sections: List[DocSection]) -> Dict[str, DocSection]:\n",
    "    return {section.id: section for section in doc_sections}\n",
    "\n",
    "def get_title_breadcrumbs(doc_section: DocSection, doc_sections_map: Dict[str, DocSection]) -> List[str]:\n",
    "    breadcrumbs = [doc_section.title]\n",
    "    current_section = doc_section\n",
    "    while current_section.parent_id:\n",
    "        parent_section = doc_sections_map[current_section.parent_id]\n",
    "        breadcrumbs.insert(0, parent_section.title)\n",
    "        current_section = parent_section\n",
    "    return breadcrumbs\n",
    "\n",
    "# Sample markdown content\n",
    "markdown_content = \"\"\"\n",
    "# Introduction to Machine Learning\n",
    "\n",
    "Machine Learning is a subset of artificial intelligence that focuses on the development of algorithms and statistical models.\n",
    "\n",
    "## Supervised Learning\n",
    "\n",
    "Supervised learning is a type of machine learning where the algorithm learns from labeled training data.\n",
    "\n",
    "### Classification\n",
    "\n",
    "Classification is a supervised learning task where the output is a categorical variable.\n",
    "\n",
    "#### Binary Classification\n",
    "\n",
    "Binary classification involves predicting one of two possible outcomes.\n",
    "\n",
    "### Regression\n",
    "\n",
    "Regression is a supervised learning task where the output is a continuous variable.\n",
    "\n",
    "## Unsupervised Learning\n",
    "\n",
    "Unsupervised learning is a type of machine learning where the algorithm learns patterns from unlabeled data.\n",
    "\n",
    "### Clustering\n",
    "\n",
    "Clustering is an unsupervised learning task that involves grouping similar data points together.\n",
    "\"\"\"\n",
    "\n",
    "# Create sample DocSection objects\n",
    "doc_sections = [\n",
    "    DocSection(\"1\", \"\", \"Introduction to Machine Learning\", \"Machine Learning is a subset of artificial intelligence that focuses on the development of algorithms and statistical models.\"),\n",
    "    DocSection(\"2\", \"1\", \"Supervised Learning\", \"Supervised learning is a type of machine learning where the algorithm learns from labeled training data.\"),\n",
    "    DocSection(\"3\", \"2\", \"Classification\", \"Classification is a supervised learning task where the output is a categorical variable.\"),\n",
    "    DocSection(\"4\", \"3\", \"Binary Classification\", \"Binary classification involves predicting one of two possible outcomes.\"),\n",
    "    DocSection(\"5\", \"2\", \"Regression\", \"Regression is a supervised learning task where the output is a continuous variable.\"),\n",
    "    DocSection(\"6\", \"1\", \"Unsupervised Learning\", \"Unsupervised learning is a type of machine learning where the algorithm learns patterns from unlabeled data.\"),\n",
    "    DocSection(\"7\", \"6\", \"Clustering\", \"Clustering is an unsupervised learning task that involves grouping similar data points together.\")\n",
    "]\n",
    "\n",
    "# Create doc_sections_map\n",
    "doc_sections_map = create_doc_sections_map(doc_sections)\n",
    "\n",
    "# Test get_title_breadcrumbs for different sections\n",
    "for section in doc_sections:\n",
    "    breadcrumbs = get_title_breadcrumbs(section, doc_sections_map)\n",
    "    print(f\"Breadcrumbs for '{section.title}': {' > '.join(breadcrumbs)}\")\n"
   ],
   "id": "f6edefbebd9c2f01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breadcrumbs for 'Introduction to Machine Learning': Introduction to Machine Learning\n",
      "Breadcrumbs for 'Supervised Learning': Introduction to Machine Learning > Supervised Learning\n",
      "Breadcrumbs for 'Classification': Introduction to Machine Learning > Supervised Learning > Classification\n",
      "Breadcrumbs for 'Binary Classification': Introduction to Machine Learning > Supervised Learning > Classification > Binary Classification\n",
      "Breadcrumbs for 'Regression': Introduction to Machine Learning > Supervised Learning > Regression\n",
      "Breadcrumbs for 'Unsupervised Learning': Introduction to Machine Learning > Unsupervised Learning\n",
      "Breadcrumbs for 'Clustering': Introduction to Machine Learning > Unsupervised Learning > Clustering\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "330d62f9d401aa05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T09:02:08.805240Z",
     "start_time": "2025-01-26T09:02:08.791482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "import random\n",
    "\n",
    "# Simulated functions for testing\n",
    "def chunk_text(text: str) -> List[str]:\n",
    "    \"\"\"Simulates chunking a text into smaller parts.\"\"\"\n",
    "    return [text[i:i+10] for i in range(0, len(text), 10)]  # Split into chunks of 10 characters.\n",
    "\n",
    "def compute_embeddings(chunks: List[str]) -> List[List[float]]:\n",
    "    \"\"\"Simulates computing embeddings for text chunks.\"\"\"\n",
    "    return [[random.random() for _ in range(3)] for _ in chunks]  # Random 3-dimensional vectors.\n",
    "\n",
    "def test_populate_doc_section_summary_chunks_at_level():\n",
    "    \"\"\"Test the workflow logic with simplified inputs.\"\"\"\n",
    "    # Simulated input data\n",
    "    doc_sections = [\n",
    "        {\"id\": 1, \"summary\": \"12312с фыва фыва 123 123 12 1ыв сыфсф ывс ывс\", \"level\": 3},\n",
    "        {\"id\": 2, \"summary\": \"Another test summary for section two.\", \"level\": 1},\n",
    "        {\"id\": 3, \"summary\": \"Final test summary for section three.\", \"level\": 2},\n",
    "\t    {\"id\": 4, \"summary\": \"йцуу йцу йцу йц уйцуйц уйцу йцуйцу йцу\", \"level\": 3},\n",
    "\t    {\"id\": 5, \"summary\": \"Хухухуху ухухх ху хух ух ухху ух уху ух хххуху думуд 3ю\", \"level\": 3},\n",
    "    ]\n",
    "    model_doc = {\"model_id\": \"1234\", \"doc_sections\": doc_sections}\n",
    "\n",
    "    # Specify the level to filter\n",
    "    level = 3\n",
    "\n",
    "    # Filter doc sections by the specified level\n",
    "    filtered_doc_sections = [doc_section for doc_section in model_doc[\"doc_sections\"] if doc_section[\"level\"] == level]\n",
    "\n",
    "    # Chunk summaries for each filtered doc section\n",
    "    chunked_summaries = [chunk_text(doc_section[\"summary\"]) for doc_section in filtered_doc_sections]\n",
    "\n",
    "    # Compute embeddings for all chunks\n",
    "    all_chunks = [chunk for summary_chunks in chunked_summaries for chunk in summary_chunks]\n",
    "    embeddings = compute_embeddings(all_chunks)\n",
    "\n",
    "    # Create points, preserving the link between chunks and doc_section.id\n",
    "    points = []\n",
    "    embedding_index = 0\n",
    "    for doc_section, summary_chunks in zip(filtered_doc_sections, chunked_summaries):\n",
    "        for chunk_index, chunk in enumerate(summary_chunks):\n",
    "            points.append({\n",
    "                \"id\": f\"doc_section_summary_level{level}_{doc_section['id']}_{chunk_index}\",\n",
    "                \"payload\": {\n",
    "                    \"summary\": chunk,\n",
    "                    \"level\": str(level),\n",
    "                    \"model_id\": model_doc[\"model_id\"],\n",
    "                    \"doc_section_id\": doc_section[\"id\"]\n",
    "                },\n",
    "                \"vector\": embeddings[embedding_index]\n",
    "            })\n",
    "            embedding_index += 1\n",
    "\n",
    "    # Print the results for testing\n",
    "    #print(\"Filtered Doc Sections:\", filtered_doc_sections)\n",
    "    #print(\"Chunked Summaries:\", chunked_summaries)\n",
    "    #print(\"All Chunks:\", all_chunks)\n",
    "   # print(\"Embeddings:\", embeddings)\n",
    "    print(\"Points:\", points)\n",
    "\n",
    "# Run the test\n",
    "test_populate_doc_section_summary_chunks_at_level()\n"
   ],
   "id": "ef34ea29ba01d665",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points: [{'id': 'doc_section_summary_level3_1_0', 'payload': {'summary': '12312с фыв', 'level': '3', 'model_id': '1234', 'doc_section_id': 1}, 'vector': [0.057234936310643025, 0.20998684916229038, 0.5690365095119472]}, {'id': 'doc_section_summary_level3_1_1', 'payload': {'summary': 'а фыва 123', 'level': '3', 'model_id': '1234', 'doc_section_id': 1}, 'vector': [0.3058681451762305, 0.7128078643256403, 0.01051870856249737]}, {'id': 'doc_section_summary_level3_1_2', 'payload': {'summary': ' 123 12 1ы', 'level': '3', 'model_id': '1234', 'doc_section_id': 1}, 'vector': [0.8762685193024727, 0.9564951172941304, 0.4525803796520377]}, {'id': 'doc_section_summary_level3_1_3', 'payload': {'summary': 'в сыфсф ыв', 'level': '3', 'model_id': '1234', 'doc_section_id': 1}, 'vector': [0.06512071531181485, 0.37245972165429275, 0.1974923887993565]}, {'id': 'doc_section_summary_level3_1_4', 'payload': {'summary': 'с ывс', 'level': '3', 'model_id': '1234', 'doc_section_id': 1}, 'vector': [0.7875515505907983, 0.7692914925609632, 0.6398830755760069]}, {'id': 'doc_section_summary_level3_4_0', 'payload': {'summary': 'йцуу йцу й', 'level': '3', 'model_id': '1234', 'doc_section_id': 4}, 'vector': [0.059780697810687844, 0.2865257599924125, 0.24277340838365702]}, {'id': 'doc_section_summary_level3_4_1', 'payload': {'summary': 'цу йц уйцу', 'level': '3', 'model_id': '1234', 'doc_section_id': 4}, 'vector': [0.8988829502683598, 0.6995588635936899, 0.24447011172645383]}, {'id': 'doc_section_summary_level3_4_2', 'payload': {'summary': 'йц уйцу йц', 'level': '3', 'model_id': '1234', 'doc_section_id': 4}, 'vector': [0.6725062922115964, 0.10871686040649797, 0.838735945079152]}, {'id': 'doc_section_summary_level3_4_3', 'payload': {'summary': 'уйцу йцу', 'level': '3', 'model_id': '1234', 'doc_section_id': 4}, 'vector': [0.12544520557034222, 0.12821860446496558, 0.7969674641347783]}, {'id': 'doc_section_summary_level3_5_0', 'payload': {'summary': 'Хухухуху у', 'level': '3', 'model_id': '1234', 'doc_section_id': 5}, 'vector': [0.6060105987268535, 0.3824029841980128, 0.27794740100531634]}, {'id': 'doc_section_summary_level3_5_1', 'payload': {'summary': 'хухх ху ху', 'level': '3', 'model_id': '1234', 'doc_section_id': 5}, 'vector': [0.42495192008712257, 0.4578801579121575, 0.6679857729544593]}, {'id': 'doc_section_summary_level3_5_2', 'payload': {'summary': 'х ух ухху ', 'level': '3', 'model_id': '1234', 'doc_section_id': 5}, 'vector': [0.5201646765478074, 0.7904105162790533, 0.04250455956228871]}, {'id': 'doc_section_summary_level3_5_3', 'payload': {'summary': 'ух уху ух ', 'level': '3', 'model_id': '1234', 'doc_section_id': 5}, 'vector': [0.19303089037410148, 0.9667163914637934, 0.3047787601970694]}, {'id': 'doc_section_summary_level3_5_4', 'payload': {'summary': 'хххуху дум', 'level': '3', 'model_id': '1234', 'doc_section_id': 5}, 'vector': [0.4333868142374159, 0.792714536920029, 0.385678922956302]}, {'id': 'doc_section_summary_level3_5_5', 'payload': {'summary': 'уд 3ю', 'level': '3', 'model_id': '1234', 'doc_section_id': 5}, 'vector': [0.9281115537744813, 0.9304511285056208, 0.33028569261287555]}]\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
